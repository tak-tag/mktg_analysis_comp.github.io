[["index.html", "マーケティング・データ分析補足資料 本ウェブサイトについて", " マーケティング・データ分析補足資料 田頭拓己 神戸大学大学院経営学研究科 2025-10-20 本ウェブサイトについて 本ウェブサイトは、マーケティング・リサーチにて広く用いられる基礎的な分析手法について、R (R studio) を用いた実行方法を紹介することを目的としている。また、本ウェブサイトは以下の図書の補足サイトとして、作成している。 田頭拓己（2025）「マーケティングデータ分析: 実務とリサーチをつなぐ」，有斐閣. そのうえで、ここではとくに分析用のコードと、図書内で省略した一部の分析手法の紹介を行っている。なお、上記の図書では分析コードだけでなく、紹介した分析手法の理論的な説明や、マーケティング・経営学領域での研究の進め方についても紙幅を割いているため、それらの内容に関心がある場合にはぜひ図書を手にとってみてほしい。 "],["rusage.html", "R と R studioに慣れる ", " R と R studioに慣れる "],["ch2intro.html", "本章の概要", " 本章の概要 本章では、統計分析ソフトウェアR（あーる）と R Studio の概要および使い方について説明する。本書では特に、R Studio と呼ばれるアプリケーションを活用した分析を想定する。さらに本章ではR Studio で活用できるプロジェクト機能を活用することを強く推奨する。本章の内容を参考に、R Studioを用いたデータ分析を行うための実行環境を整えてほしい。 R は統計、データ解析、統計グラフ作成のためのオープンソースソフトウェアである。なお、Rを用いる際には、多くの場合) R studio、Jupyter notebookや、Rコマンダーのようなユーザーインターフェイスが利用される。そしてRを使用する際には (Rコマンダーを使わないかぎりは) 基本的にソースコードを入力し計算、分析を行う。Rを用いる際に最もよく使われる環境（アプリケーション）のひとつがR studioであり、本書においても基本的にはR studioを用いることを前提とするが、R studioをデスクトップにインストールし利用する場合には、Rそのものもインストールしておく必要があることに注意が必要である。R studioは現在、Positとも呼ばれており、以下のサイトからダウンロードが可能である（https://posit.co/download/rstudio-desktop/）1。このリンクにアクセスし、自身の環境に適したRStudio Desktop ソフトウェアの実行ファイルやディスクイメージファイルをダウンロードしてほしい。そしてファイルをダウンロードしたら、それを開くことで表示されるインストーラーの手順に従い、RStudioをダウンロードしてほしい。 また本書では、Posit Cloudという、アカウント登録を行うことでブラウザ上でR studioを利用できる環境も紹介する。R studio Desktop版 の利用においては、データの所在地（ディレクトリ）設定などによってエラーが生じることが多々あり、個別のPC環境に合わせて対応、設定を行う必要がある。そのため、まとまった人数に対応する必要がある講義で R studio を活用する場合や、R studio のインストールに苦労する初学者においてはまずPosit cloud と呼ばれるクラウド版を利用し、本書で紹介するような分析作業になれることを勧める。しかし、Posit cloud のフリーアカウントには、利用可能な時間やデータ容量に制限があるため、自身の研究や仕事等でデータ処理や分析を行う場合にはR studio デスクトップ版（通常はR studio IDEのフリーバージョンで十分）をインストールし、利用してほしい。 なお、Posit社のウェブサイトの構成は時期によって変化する可能性がある。もし、RStudio Desktopのダウンロードサイトが見当たらないときにはPosit ウェブサイト内で “Rstudio” と検索してほしい↩︎ "],["desktop.html", "R studio デスクトップ版の利用", " R studio デスクトップ版の利用 R studioは、Rを利用するためのアプリケーションである。R単体で使うよりも便利な機能が搭載されており、R studioを使うことでプログラミング作業を容易にすることが可能になる。最も大きな特徴としては、Rでの操作、分析を実行するための「コンソール画面」と、実行したい操作、分析のコードを記述しておく「Rスクリプト」と呼ばれるテキストファイルを一つの画面内に同時に表示できることである。そのため、Rに実行してほしいコマンドをテキストデータのように記述、修正し書き溜めておける一方で、その実行もスムーズに行え、結果も同画面内で確認することができる。 R studio はR をより便利に使うためのツールであるため、利用者はまず、R と R studioの両方をインストールする必要がある。Rは以下のサイト（https://ftp.yz.yamagata-u.ac.jp/pub/cran/）等からダウンロードし、インストールすることが可能である。当該ウェブサイトにアクセスすると、Windows用、Mac用、Linux用のソフトウェアが選択できるため、ユーザー自身の環境に適したバージョンを選択してほしい。Windowsユーザーの場合は、“install R for the first time” と書かれているリンクから自身の適した条件を選択し、実行ファイルをダウンロードしてほしい。Macユーザーの場合には、自身の使っているMacのバージョンに適したパッケージファイルを選択し、ダウンロードしてほしい。インストーラーやパッケージファイルをダウンロードした後はその後のソフトウェアインストール手順指示に従い、Rをインストールすること。 R studio のインストールは、以下のリンクから 行うことができる（https://posit.co/download/rstudio-desktop/）。なお下図は、MacOSを使ったデバイスの場合のインストール画面を表している。RStudioのインストールにあたっては、このリンクにアクセスし、自身の環境に適したRStudio Desktop ソフトウェアの実行ファイルやディスクイメージファイルをダウンロードしてほしい。なお、特別な事情がない限り、無料版で十分分析が可能である。そしてファイルをダウンロードしたら、それを開くことで表示されるインストーラーの手順に従い、RStudioをダウンロードしてほしい。 Rstudio Desktop インストール画面（Mac例） なお、WindowsでのRおよびR studioのインストールには注意が必要である。特に、Rを用いる講義を受け持っていると、Windowsユーザーを中心に新たなパッケージのインストールができないなどのトラブルが頻発する。これらの問題点を調べると、(1) 文字コードによる文字化けの問題、(2) ユーザーアカウントのホームディレクトリ名に日本語（全角）が利用されていること、(3) Rのライブラリが(勝手に) One drive 上に作成されることが原因であることが多かった。これに対して、 R の version 4.20以降からは、UTF-8の文字コードに対応したり、デフォルトでのRのインストール場所の変更（One drive上でない）が行われたりと、問題の改善が図られている。また、自身のホームディレクトリの名前が全角文字であるときは、ホームディレクトリ以外のローカルディレクトリを設定したほうが良い。この点に関する対応には、三重大学の奥村先生によって以下のウェブサイトに説明が記載されているので、詳しくはそちらを参照してほしい（https://okumuralab.org/~okumura/stat/R-win.html）。 "],["project.html", "プロジェクト機能について", " プロジェクト機能について R および R studio のインストールが完了したら、アプリケーションを起動する。 アプリケーションを起動すると、デフォルトでは以下のような R Studio環境画面が表示される。 新しいRstudio 画面 Rstudioは、上記の図のような画面構成をしている。Rstudioの画面を構成する主なウィンドウはペインと呼ばれ、(1) RスクリプトでRコードの入力・編集に用いる”Source”、(2) Rの命令を直接入力し結果も表示される”Console”がなどが主な要素としてある。また、その他利用しているデータ情報、パッケージ、履歴など様々なタブが存在する。Rstudioの初回起動時にはSourceのペインは収納されているため、 Rスクリプトファイルを作成する必要がある。Rstudioは基本的に4分割画面で表示され、各ペインの配置については、Tools \\(\\rightarrow\\) Global option \\(\\rightarrow\\) Pane Layoutより変更が可能になる。Rstudioを操作する上で、基本的に重要となる情報は、(1) Source、(2) Console、(3) データやプロットに関する環境情報の3点であるので、以下のような配置がおすすめである。 左上 or 下: Source 左下 or 上: History (ただし、さほど重要ではないので畳んだ状態にしておく) 右上 or 下: Console 右下 or 上: 複数タブをまとめ 配置の目的はあくまで、必要な情報を同一画面上に表示することであるため、自身のやりやすい配置を考えてアレンジしてほしい。 R studio を利用する際には、「プロジェクト」機能を使うことを勧める。プロジェクトは、互いに関連し合ったファイルの集まりを指す。Rを通じた分析では、たくさんのファイルを扱うことになる。例えば、複数のRスクリプトやデータセット、加工したデータセットの保存、分析結果、出力された図表などがある。これらのファイルを手作業で一括管理することは困難である。むしろそのような管理作業に認知的な負担を費やしたくないというのが分析者の本音である。プロジェクト機能を使うことにより、作業ディレクトリとファイルの保存先をひとまとまりに指定できるため、ファイル管理の手間がなくなる。 新しいプロジェクトを作成するシンプルな方法が、Fileから作成する方法である。具体的には、File -&gt; New Project -&gt; New Directory -&gt; Create New Project -&gt;Directory nameの指定 -&gt; プロジェクトの設置場所（ディレクト）の指定、という手順で作成する。 R をデスクトップ上で利用する際には、基本的には自身のPC内にあるデータの所在地（ディレクトリ）を特定することでデータの操作や分析を行う。これに対してプロジェクト機能を利用することでそのプロジェクトを実行している際に参照するワーキングディレクトリを固定することが可能になる。この機能によってR studioを通じたデータ処理や分析作業が容易になり、不要なトラブルを避けることが可能になるため、デスクトップでR studioを使う場合には可能な限りプロジェクト機能を利用してほしい。 "],["basics.html", "Rの基本操作", " Rの基本操作 ここでは、Rを使用する上での基本的な操作方法を紹介する。Rはコマンド（命令）をconsoleを通じて実行することで動かすことができる。例えば四則演算であれば、以下のように命令し、計算が実行できる。 1 + 2 ## [1] 3 5 - 10 ## [1] -5 3 * 8 ## [1] 24 1/2 ## [1] 0.5 基本的に一つのコマンドは1行に書き、数字、演算記号、スペースは半角で入力する。以下は、べき乗、平方根、自然対数を計算するためのコマンドで計算できる。 2^3 ## [1] 8 sqrt(2) ## [1] 1.414214 log(2) ## [1] 0.6931472 Rは、ベクトルや行列の計算も可能である。c() という関数を用いると、ベクトルを作成できる。例えば、c(1, 3, 5) というコマンドによって(1, 3, 5)というベクトルが作成できる。作成したベクトルを使って以下のような計算も可能である。 c(1, 3, 5) + 1 ## [1] 2 4 6 ベクトルは、連続した数字の列を生成するための演算子である : を用いても作成することができる。例えば、1から100の整数を要素とするベクトルは以下のように作成することが可能である。 1:100 ## [1] 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 ## [19] 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 ## [37] 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 ## [55] 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 ## [73] 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 ## [91] 91 92 93 94 95 96 97 98 99 100 また、ベクトルの要素は文字列でも構わない。 cities &lt;- c(&quot;Tokyo&quot;,&quot;Osaka&quot;,&quot;Kobe&quot;) cities ## [1] &quot;Tokyo&quot; &quot;Osaka&quot; &quot;Kobe&quot; 上記の計算方法に加え、Rが持つ重要な特徴に、オブジェクトの定義がある。Rでは、任意の行列、ベクトル、数値などに名前をつけ定義したうえで、それを用いた計算を行うことができる。なお、Console上で以下のように定義（実行）したオブジェクトはenvironmentタブ内に表示されるため、各自確認をしてほしい。なお、定義したオブジェクトの確認・出力も簡単に行えるが、大文字と小文字は区別されるため、注意が必要である。 a &lt;- 1 b &lt;- 2 a ## [1] 1 A ## Error: object &#39;A&#39; not found また、定義したオブジェクトを用いた計算も実行できるため、各自以下の計算を実行し、結果を確認してほしい。 a + b a / b a ^ b なお、先程のベクトル操作と組み合わせ、ベクトル名 [i] とすることで、ベクトルの i 番目の要素にアクセスすることができる。例えば、以下のaとbというベクトルから特定の要素を取り出すことを考える。なおこの場合、同時に複数の要素を取り出すこともできる。 a &lt;- seq(10, 100, length = 10) b &lt;- 10:1 aの2番目の要素 a[2] ## [1] 20 bの2番目の要素 b[2] ## [1] 9 aの3-5番目の要素 a[3:5] ## [1] 30 40 50 aの1,3,5番目の要素 a[c(1,3,5)] ## [1] 10 30 50 分析で繰り返し必要になる機能がRで使えないときは、function()関数を使って、新たな関数を作成できる。例えば、最大値と最小値を並べて表示したい場合を考える。そのために、ここでは ‘mm’ という新たな(オブジェクトxの最小値と最大値で構成されるベクトルを返す)関数を作ってみる。 mm &lt;- function(x){ c(min(x), max(x)) } そして上記の関数を利用して、以下のオブジェクト a, b の最小値と最大値を出力する。 a &lt;- c(1, 5, 100, 2, -8, 7) b &lt;- c(1, 6, 8, 0, 120) mm(a) ## [1] -8 100 mm(b) ## [1] 0 120 しかし、すべての関数を自作するのは難しい。Rでは様々な計算を実行するための関数が用意されており、多くのマーケティング研究においては既存の関数を用いることで対応が可能である。実は上記のmm関数の中で使っている “min”や”max”も、それぞれ最小値と最大値を返す関数である。他にも例えば、meanや median があり、これらはそれぞれ平均値と中央値を計算するための関数である。 関数の利用においては例えば、f()のように関数名 “f” のあとにカッコをつけて表記する。()の中には、引数（arguments）を用い、計算に必要な情報を指定することが必要となる。例えば、seq() という関数を用いて、2以上20以下の偶数の数列(sequence)を作ることが可能である。seq(from = x, to = y, by = z)は等差数列を作るための関数であり、第一の引数で最初の数、第二の引数で最後の数、第三の引数で間隔を指定することで数列を作成できる。以下で提示される二通りの表記ではどちらも同じ結果を返す。 seq(from = 2, to = 20, by = 2) ## [1] 2 4 6 8 10 12 14 16 18 20 seq(2, 20, 2) ## [1] 2 4 6 8 10 12 14 16 18 20 特定の関数に対する引数を確認したい場合は ‘?関数名’とconsoleに命令することで確認が可能になる。例えば、seq関数について知りたければ、’?seq’ で確認できる。 Rに元から含まれている関数以外にも他者が開発してくれた関数も存在する。そしていくつかの関数をまとめたpackagesが多数存在する。これまで世界中の開発者たちが作成したパッケージを公開してくれている。パッケージは何らかの目的や課題を達成することを目的に構成されたコードライブラリであり、それらをインストールし、各セッションごとに起動することで利用できる。 CRAN（The Comprehensive R Archive Network、Rに関するコードとドキュメントを配布するサーバーネットワーク）で公開されているパッケージは、install.packages()でインストール可能である。また、Rstudio の場合、ペインからpackagesタブ\\(\\rightarrow\\)Install\\(\\rightarrow\\)パッケージ名の入力という手順でもインストールが可能である。そしてインストール済パッケージは、library() によって起動することで、活用可能にある。ここで注意しておきたいのは、library()によるパッケージの起動はセッションごとに実行しないといけないという点である。まずは以下の通り、本講義で用いる “tidyverse” パッケージをインストールし起動してみる。“tidyverse”は、複数のパッケージから構成されているパッケージであり、データの整形・分析を行うために役立つ複数のパッケージをまとめてインストール・起動できる。 install.packages(&quot;tidyverse&quot;) library(&quot;tidyverse&quot;) "],["rscript.html", "R スクリプトのすゝめ", " R スクリプトのすゝめ Rstudio環境で作業を行う際には、Consoleに直接コマンドを入力するのではなく、‘.R’ という拡張子のファイルを使って、「Rスクリプト」を作成することを勧める。RスクリプトはRでの分析に対応しRコマンドの集まりとして記されるファイルであり、SourceエディタからRスクリプトに記載されたコマンドを、Consoleを通じて実行する。 Rスクリプトを用いることの重要性は、コマンドの修正可能性と、分析の再現性という二点から理解できる。まず修正可能性として、そもそもコマンドを書くうえでは大小様々な誤りが付き物である。このような間違いに対応し適宜修正を加えていくためには、実行するコマンドを一つ一つ console に直接記載するのではなく、Rスクリプトとして分析過程を記録し、その内容に基づき記載、修正を加えることが好ましい。 第二に再現性においては、Rスクリプトとしてデータ整形・分析のプロセスを文書ファイルとして保存しておくことで研究者自身もしくは第三者が分析を再現することが可能になる。これは研究プロセスの客観性を高め、分析結果の信頼性を高めるために非常に重要な要素である。 これらに加え、Rスクリプトの利用は研究者個人の研究遂行上の利点もある。自身が行った研究であっても分析の細部に関しては時間経過とともに忘れてしまうものである。その際に、Rスクリプトによる分析プロセスの追跡可能性が役に立つ。また、同様の分析を再度別データで実施する場合も、既存のRスクリプトを応用することで効率的に分析が可能になる。これらに加え、共同研究において他の研究者と分析プロセスを共有する場合にもRスクリプトが役に立つ。 Rスクリプトを書く 先述のRスクリプトの利点を活かすために、Rスクリプトの作成においては、いつ作成されたなんのためのファイルなのか、そしてファイル内に記載されているコマンドがどのような意図によるものなのかがわかるように書くべきである。そのための重要になるのがコメント機能である。一つの行の中で#記号よりも後ろの部分はコメントとして処理（コメントアウト）される。コメントアウト機能とは、プログラムコードにおいて、分析や実行から除外するための指示である。この機能を使い、コメントで自然言語による説明を加えることで、コマンドの説明や意図等、自分や他人がスクリプトを見返して内容を理解できるようにする。例えば、Xという変数の平均値を求める場合、以下のようにRスクリプトを書くようにする。 #Xの平均値を求める。 mean(X) Rスクリプトは、Rstudioの左上にある+ボタンから新規作成可能である。ここでは試しに、新規Rスクリプトを作成し、“mktg01.R” という名前で保存してほしい。保存したRスクリプトはファイルから開くことができる。“mktg01.R”ファイルを作成したら、試しに以下のコマンドを書き込み、実行してほしい。Rスクリプトからコマンドを実行する際には、コマンド記入後、Rスクリプト上で実行したい行にカーソルを合わせた状態でcommand (control) + Return (Enter)を入力する。もう一度同じキーを押すと、2行目のコマンドが実行される。これらを実行することで、Rコンソール上に、下記と同じ結果が出ていることを確認してほしい。なお、コマンドを記入の際には、こまめに command (control) + s により保存することを心がけるようにしてほしい。 a &lt;- 9 sqrt(a) ## [1] 3 また、Rスクリプトを作成する際には、ファイルの冒頭に以下の説明を書き込む習慣をつけると後々見返すときに便利である。 ファイル名 目的 作成者 作成日 最新更新日 例えば、上記の内容とコマンドを含めた “mktg01.R” ファイルは、以下のようになる。 Rスクリプト例 "],["ch2summary.html", "本章のまとめ", " 本章のまとめ Rはデータの管理、分析、図表の作成を行うことができる統計分析プログラミング言語である。 Rを動かすには、コマンドと呼ばれる命令をコンソールを通じて実行する。 コマンドは基本的にRスクリプトに書き込んでからcommand (control) + Return (Enter)で実行する。 Rスクリプトにはコマンドだけでなくコメントを使った説明も追加する。 分析には既存の関数やパッケージを使うことが多い。 "],["positcloud.html", "コラム：Posit cloudを使ってみる", " コラム：Posit cloudを使ってみる R studioをより手軽に利用できるサービスとしてPosit Cloudがある。Posit Cloudはブラウザを通じてR studio環境を利用できるサービスであり、アカウント登録をするだけでよく、コンピュータへのRおよびR studioのダウンロードとインストールが不要である。 Posit Cloudの利用方法はとても簡単である。大まかな利用までの流れは以下のとおりである。 以下のリンク（https://posit.co/）からサイトへアクセスし、ProductsタブからPosit Cloudを選択する。 その後、進んだ画面で “Get Started” \\(\\rightarrow\\) （特別な理由がなければ）Free planを選択し “Sign up” \\(\\rightarrow\\) 好きな方法でアカウントを作成する。 登録が完了すると、自身のアカウントのホーム画面へ移動する。新しいR studio セッションを開始するためには、画面右上の New projectボタンを押し、“New Rstudio Project” を選択する。 New projectのセットアップが完了すると、Studio環境画面が表示される。 新しいRstudio 画面 このような手順でデスクトップ版と同様のR studio 画面にブラウザからアクセスすることができる。これにより、（容量の制限はあるものの）デスクトップ版と同様の分析を実行することができるため、大人数講義や、RやR studioのインストールに不安のある方はこちらのサービスを利用してほしい。 "],["ch2reference.html", "参考文献", " 参考文献 浅野雅彦・矢内勇生 (2018) 「Rによる計量政治学」, オーム社. ランダージャレド（2015）「みんなのR 第2版」，高柳新市・牧山幸史・蓑田高志訳，マイナビ. "],["handling.html", "データ整理と要約・可視化 ", " データ整理と要約・可視化 "],["Ch3intro.html", "本章の概要", " 本章の概要 本章では、Rを用いたデータの処理と記述的な分析について紹介する。マーケティング領域では、様々なタイプのデータを扱うが、どのようなデータであってもデータを取り込み、分析可能な形に処理した後、データの特徴について確認することが必要になる。最終的に高度な統計分析を行うことを想定していたとしても、自身の獲得したデータの特徴を確認することは非常に重要である。そのため、本章ではデータの読み込みやデータ処理といった、分析の前に必要な技術的過程を紹介する。 データセットの構築が完了したあとは、分析を行うのだが、本章ではRを通じて実行可能な基本的なデータ分析手法を紹介する。Rには、様々な計算を実行するための関数が用意されており（例、mean, median, sqrt 等）、これらを使えば、分析者はシンプルなコマンドで分析が可能になる。関数のは f(argument) のように関数名 f のあとにカッコをつけて表記することで利用する事ができる。なお、argument は日本では引数とよばれ、計算に必要な情報の指定である。関数の利用において作業者は具体的な関数名とそれに対応する引数を指定する必要がある。例えば、データ（列ベクトル）x の平均値を計算したい場合には、以下のようなコマンドで実行できる。 mean(x) ただし、 na.rm = TRUE はデータに欠損値がある場合に、それを無視して（欠損値でない観測値のみで）計算を行うための引数である。 Rの作業として本章では主に、1. データの読み込み（csv, excel, etc.）、2. dplyrの利用とデータ整形、3. パイプ演算子を用いた複数処理の実行、について学ぶ。なお、これらの作業は、統計的な分析を実行する前のデータ前処理としても広く使われるものなので、データ分析をしたいと考える人達にとってはとても重要なスキルになる。 分析可能な形にデータを処理した後は、データの特徴を確認することが必要になる。具体的には、記述統計や図示化を用いて、特定の変数の分布や変数間の関係について確認を行うことが重要である。この過程により、調査の背景にある実情を把握できるとともに、入手したデータ（のコーディングなど）にエラーがないかを確認することにもつながる。本章では、関数を用いた基本的な記述統計の計算はもちろん、先述のパイプ演算子を用いて、ある特徴を持つ観測における記述統計の計算などを簡単に行う方法も紹介する。 また、二変数間の関係を捉えるための基本的な指標である相関係数についても説明する。そこでは、相関係数の意味や係数の解釈における注意点についても紹介した後、データを可視化することの重要性も合わせて説明する。データの可視化においては主に、ggplot2 というパッケージを用いた方法を紹介する。本章では主にRパッケージ内に含まれているデータ例を用いて、可視化の方法を紹介するため、読者においてはぜひ自身の関心のあるデータを用いて実行してみてほしい。 "],["readData.html", "データの読み込み", " データの読み込み 本節で用いるパッケージをまだインストールしていない読者は、以下のコマンドを用いてインストールしてほしい。また、インストールを完了したら、library()関数によって各パッケージを起動し、作業に備えてほしい。 install.packages(c(&quot;tidyverse&quot;,&quot;readr&quot;,&quot;readxl&quot;)) library(tidyverse) library(readr) library(readxl) ここからは、データセットを用いた情報の取り込みとデータ処理作業を行っていく。多くの場合、R外部で作成されたデータを取り込み利用するのだが、あるソフトウェアで作成・保存されたデータセットが他の環境で利用できるとは限らないという点に注意が必要である。そのため、ソフト特性に依存しない汎用的な形式を使うことが好まれることも多い。汎用性の高いファイル形式の代表的な例がCSV (comma separated values) である。以下は、mktData.csvという架空のファイルをdfというオブジェクト名で取り込むための、見本コードである。ここで用いる関数は、readrというパッケージのread_csv() という関数である。なお、以下のコードは、実在しない ’mktData.csv’というデータセットを引数に利用した見本コードであるため、このコードをそのまま実行してもエラーを返すだけであることに注意をしてほしい。実際には、自身が利用するファイル名を指定してファイルを読み込むことになる。なお、以下のコードの2行目は、データの1行目に変数名（列名）が含まれていない場合の引数の指定方法である。また、下記コードで利用している :: は用いるパッケージを指示するための演算子である。これにより、library() を用いなくても、指定したパッケージ内の関数を利用することができる。 df1 &lt;- readr::read_csv(&quot;mktData.csv&quot;) df2 &lt;- readr::read_csv(&quot;mktData.csv&quot;, col_name = FALSE) なお、R studioデスクトップ版を利用している場合には、ファイルが格納されているディレクトリ名も指定する必要がある。Rにおいては様々なファイルを入力・出力することになるため、利用するディレクトリが一貫していないとそれだけで作業が煩雑になる。そのため、??章 で紹介している「プロジェクト機能」必ずを活用するようにほしい。 ここで用いるデータは、有斐閣ウェブサイトを通じて配布している。そのため、読者においては各自のコンピュータにダウンロードし、分析用に活用してほしい。ここではまず、分析に利用するデータを格納するディレクトリを作成するコードを紹介する。以下のコードは、プロジェクトを作成しそのためのディレクトリを指定していることを前提にしている。 具体的は、以下の通りdir.create() を使ってproject内に新たに data というディレクトリ（フォルダ）を作成する。 dir.create(&quot;data&quot;) 新たなディレクトリを作成したら、そこに、ウェブサイトよりダウンロードしたデータを入れてほしい。ここではまず “2022idpos.csv”というデータを用いる。データが無事 data ディレクトリに含まれたら、以下のコマンドによってそのデータファイルをR の作業スペースに読み込み、それに “idpos” というオブジェクト名を定義する。なお、ここで分析者はディレクトリを指定することも必要になる。また、コード内の na は、欠損値がどのように保存されているかを指定するための引数であり、もし欠損値が空欄であればnaによる指定は必要ない。 idpos &lt;- readr::read_csv(&quot;data/2022idpos.csv&quot;, na = &quot;.&quot;) 問題なくデータを読み込むことができたら、そのデータの冒頭数行を head() 関数によって表示する。head() 関数の結果によって、このデータセットのうち、4つの変数（列）について6つの観測（行）が表示されるはずである。なお、R studio 画面内の Environment タブからこのidposデータが3000行、5列のデータセットであることを確認できる。 head(idpos) ## # A tibble: 6 × 4 ## id date spent coupon ## &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 12 2019/9/25 14326 1 ## 2 32 2019/9/10 10232 1 ## 3 30 2019/9/9 6881 1 ## 4 29 2019/9/4 6365 0 ## 5 46 2019/9/10 7595 1 ## 6 44 2019/9/14 7858 0 また、読み込んだデータ特徴の確認は他の関数でも実行できる。例えば、name() 関数を使えば、データ内の変数名 (列名) を確認できるし、tidyverseに含まれる glimpse() 関数によってもデータの冒頭数行を含むいくつかの情報を返してくれる。 names(idpos) ## [1] &quot;id&quot; &quot;date&quot; &quot;spent&quot; &quot;coupon&quot; glimpse(idpos) ## Rows: 3,000 ## Columns: 4 ## $ id &lt;dbl&gt; 12, 32, 30, 29, 46, 44, 44, 32, 3, 34, 36, 3, 42, 18, 38, 4, 19… ## $ date &lt;chr&gt; &quot;2019/9/25&quot;, &quot;2019/9/10&quot;, &quot;2019/9/9&quot;, &quot;2019/9/4&quot;, &quot;2019/9/10&quot;, … ## $ spent &lt;dbl&gt; 14326, 10232, 6881, 6365, 7595, 7858, 9405, 1821, 8375, 1828, 6… ## $ coupon &lt;dbl&gt; 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, … なお、このidposデータは、POS (Point of sales) という小売店レジでの取引データとロイヤルティプログラムなどの会員IDを含むID-POSと呼ばれるデータを想定して簡略化し作成した、演習用人工データである。データには、小売店舗での取引日（date）、金額（spent）、クーポン利用の有無 (coupon)、性別 (gender) が含まれている。本来のPOSデータは、より詳細な日時や具体的な製品単品レベルの取引品目など、より詳細な情報が含まれているはずだが、ここでは簡単化のためにこのようなデータにしている。また、もしスプレッドシート形式で表示したい場合には View() 関数をconsoleに直接入力することでそれが可能になる。例えば、idposデータを用いて以下のようなコードを入力することで、Sourceウィンドウに新しいタブができ、そこにデータセットが表示される。 View(idpos) "],["normalization.html", "データの整形", " データの整形 tidyverse の活用 データの整形には、tidyverseパッケージ群に含まれるdplyrというパッケージを用いる。作業では、tidyverseをインストール・起動しておけばdplyrも利用できるため、特に心配する必要はない。dplyr には、いくつもの便利な関数がふくまれているが、本節では主に以下の関数および機能を紹介する。 summarize(): データセットを関数内で定義した統計量等を用いて要約された新しいデータセットに変換するための関数 mutate(): データセットに新しい変数を追加するための関数 filter(): データセットから、関数内で指示する特定のレコード（行）を残す（フィルタリング）するための関数 select(): データセットから、関数内で指示する特定の列を抽出するための関数 arrange(): データセットから、関数内で指示する順番で並べ替えるための関数 パイプ演算子 %&gt;%: 前（左）の関数の出力を次（右）の関数の入力として渡すため演算子 summarize は、ある変数の平均値や標準偏差などの記述統計量を計算することができる関数である。例えば、dataというデータセットに含まれる var_name という変数の平均値を計算し、それを M という変数名として定義する場合、以下のコマンドを用いる（以下のコマンドは見本コードである）。 summarize(data, M = mean(var_name)) mutate は、データセットに引数内で指定した定義の変数（列）を追加する関数である。例えば、以下の見本コードにような指示によって、data というデータセットに対し、definition で定義した変数をnew_varとして追加することができる。実際の分析でdefinitionを定義する場合には、様々な関数や論理式を利用する事が多い。例えば、“new_var = var1/100” という定義を用いれば、var1を1/100倍した値をnew_varとして定義することになる。また、“new_var = var1 – mean(var1)”という定義を用いれば、var1の観測値からvar1の平均値を引いた値をnew_varとしている。なお、このような操作化を一般的に「中心化」と呼ぶ。 mutate(data, new_var = definition) また、mutate関数の利用においては、条件分岐を用いた変数の作成を行うこともある。そのように、研究者がある変数の値に応じて異なる値を変数を作成するときには、mutate内で、ifelse()関数を用いる事が多い。ifelse() 内の第一引数は条件、第二引数は条件が満たされたときの処理、第三引数は条件が満たされないときの処理をそれぞれ表す。なお、特定の条件の指定には “==” （同値）, “&gt;=”（以上）, “&lt;=”（以下） を使う。具体的には、var1 が2ならば1をとり、それ以外であれば０をとるという条件でnew_varを作成するという指示は、以下のようになる（以下は見本コードである）。 mutate(data, new_var = ifelse(var1 == 2, 1, 0)) filter関数は、データから特定の条件に合致する行だけ取り出す場合に用いる関数である。例えば、男性（gender == “male”）のサンプル情報のみ抽出したい場合には以下のような指示になる。 filter(data, gender == &quot;male&quot;) なお、特定の条件以外のものを指定したいときは、 という論理式 “!=” (not equal) を使う。男性以外の行を選ぶための指示は、以下の通りになる。 filter(data, gender != &quot;male&quot;) select関数は、特定の変数（列）を選んで新たなデータフレームを作成することができる関数である。例えば、dataというデータセットから、var1、var2、var3 という変数（列）を抽出して、data2というdataframeとして定義するには、以下のような指示になる。 data2&lt;- select(data, var1, var2, var3) 反対に、取り除きたい変数を指定するときには、以下のように “-” を使う。 data2&lt;- select(data, -var1) 列の指定方法には、いくつかのやり方が存在する。並んでいる列をまとめて指定するときは:（コロン）を使う。例えば、var1からvar5までの列をまとめて抽出し、それをdata2として定義するのは以下のようにできる。 data2&lt;- select(data, var1:var5) また、tidyverseのstarts_with()（ends_with()）を使うことで、変数名の冒頭（末尾）が特定の文字列から始まる変数を指定するようなことも可能である。例えば、“v” という文字から始まる変数を取り出すための指示は、いかのようになる。 data3&lt;- select(data, starts_with(&quot;v&quot;)) arrangeは、データの並べかえを可能にする関数である。例えば、以下ではvar1の値が小さい順（昇順）に並べ替えるような指示を示す。一方で、降順にする場合は、desc(var1)と引数を指定する必要がある2。 data2 &lt;- arrange(data, var1) data2 &lt;- arrange(data, desc(var1)) また、tidyverse環境において、変数名を変更することも、rename() 関数で可能になる。以下の指示によって、var_name という変数を new_name に変更する事ができる。 data3 &lt;- rename(data2, new_name = var_name) dplyr を活用すると、パイプ演算子（%&gt;%）が使える（ショートカット: command (control) + Shift + m）。パイプ演算子は、左側の処理結果を演算子右側の関数の第一引数として利用するための指示である。たとえば、以下のコマンドではまず \\(\\small 10-6\\) が計算され、その結果である “4” が sqrt() の引数として利用される（sqrt(4) は 2）。 (10-6) %&gt;% sqrt() ## [1] 2 パイプ演算子は、複数のデータ操作処理を連続して行う際に便利である。例えば、顧客の情報を含むデータセット(data)から、男性に該当する情報のみを抽出し、var1(例、購買額)についてのランキングを作成したうえでいくつかの変数を含んだデータセット（new_data）を作成する場合を考える。その際に実行すべき作業とそれらに対応する関数は以下のように示すことができる。 男性の情報だけ抜き出す(filter) Var1の値について降順に並べ替える(arrange) 第一位から最下位までの順位を割り当てた ranking 変数を作る(mutate) var1 , var2, var3, var4, rankingだけ残し(select) new_dataとして定義する 上記の作業を一気に行うためのコードをパイプ演算子を使わずに書くと以下の様になる（以下は見本コード）。 new_data &lt;- select(  mutate(   arrange(    filter(data, gender == &quot;male&quot;),    desc(var1)),    ranking = 1:n()),   var1, var2, var3, var4, ranking) パイプ演算子を使わない場合、先に実行する処理が内側に来ており、一見して何を行っているのか理解するのが難しい。一方でパイプ演算子を使い、左側の処理結果を演算子右側の関数の第一引数として利用すると、以下のように書き換えることができる。 new_data &lt;- data %&gt;% filter(gender == &quot;male&quot;)%&gt;% arrange(desc(var1)) %&gt;% mutate(ranking = 1:n()) %&gt;% select(var1, var2, var3, var4, ranking) パイプ演算子の利用により、各関数の処理を一つの行で示せる。また、処理の順番通りに関数を記載することが可能なので、コードの記述容易性と可読性の両方が高まる。また、パイプ演算子による操作は次の関数の第一引数以外に反映されることも可能である。第一引数以外の引数に左側の処理結果を反映させる際には、該当する箇所に “.” （ドット）を使う。たとえば、\\(\\small 10-2\\)の計算結果を用いて2から8までの偶数で構成されるベクトルを返すためのコードは以下のように書くことができる。 (10-2) %&gt;% seq(from = 2, to = ., by = 2) ## [1] 2 4 6 8 データの整形・処理作業が終わったら、そのデータを自身のコンピュータ内のストレージに保存したいと考えるかもしれない。Rでは、外部への書き出しという形でデータを保存することが可能である。例えば、df という名前のデータフレームをnew_dataというファイル名で、dataというディレクトリにcsv形式を用いて保存するためには、以下のようなコードを用いる（以下は見本コード）。また、csv以外にもファイル形式は選択可能であり、例えばRのデータ形式(.Rds)で保存する場合には、“#Rds” 以降のコードを用いる。 readr::write_csv(df, path = &quot;data/new_data.csv&quot;) #Rds readr::write_rds(df, path = &quot;data/new_data.Rds&quot;) 企業データの処理 これまでに学んだデータ処理の手法を実行するために、本節では、 MktRes_firmdata.xlsxデータを用いる。このデータをwebサイトより data ディレクトリにダウンロードし、以下の要領で読み込んでほしい。 firmdata &lt;- readxl::read_xlsx(&quot;data/MktRes_firmdata.xlsx&quot;) このデータは、小売・サービス分野の企業約160社（企業数は年によって異なる）に関する2010年から2019年までの財務データである（計1440件）。このデータは、日本生産性本部における顧客満足度調査の対象になっている企業リストを作成し、その企業の中から金融領域の企業や、データを入手できなかった一部の企業を教育的意図から排除したものである。したがって、日本の小売・サービス分野において全国的に知名度のある代表的な企業の財務データ（の一部）だと考えられる。 なお、本データには以下の変数が含まれており、データ内の単位は従業員数（人）を除き百万円である。 fyear: 決算年 legalname: 企業名 ind_en: 日経業種名（英文） parent:親会社名（もしあれば） fiscal_month: 決算月 current_liability: 流動負債 ltloans: 長期借入金 total_liability: 負債合計 current_assets: 流動資産 ppent: 有形固定資産 total_assets: 資産合計 net_assets_per_capital: 純資産合計／資本合計 sales: 売上高 sga: 販売費及び一般管理費 operating_profit: 営業利益 net_profit: 当期純利益 pnet_profit: 親会社株主に帰属する当期純利益（連結）／当期利益（単独） re: 利益剰余金 adv: 広告・宣伝費 labor_cost: 人件費 rd: 研究開発費 other_sg: その他販売費及び一般管理費 emp: 期末従業員数 temp: 平均臨時従業員数 tempratio: temp/(emp+temp) indgrowth: 産業成長率 adint: 広告集中率（adv/sales） rdint: 研究集中率（rd/sales） mkexp: (sga - rd) / sales op: operating_profit / sales roa: pnet_profit / total_assets 本データセットは、複数年にわたる複数サンプルからのデータであり、一般的にこのような構造のデータをパネルデータという。パネルデータの分析の概要は ?? 節で紹介している。 ここではこのデータを用いて、以下の作業を行う。 2018年度のデータのみを抽出する。 企業名、年、売上高、人件費、期末従業員数、平均臨時従業員数のみの変数を含むデータセットにする。 労働単価（人件費/（期末従業員数+平均臨時従業員数））変数を作成する。 労働単価の高い順に並び替えてトップ10企業を出力する。 firm2018_check &lt;- firmdata %&gt;% filter(fyear == 2018) %&gt;% select(legalname, fyear, sales, labor_cost, emp, temp) %&gt;% mutate(wage = labor_cost/(temp+emp), na.rm=TRUE) %&gt;% arrange(desc(wage)) head(firm2018_check, n = 10) ## # A tibble: 10 × 8 ## legalname fyear sales labor_cost emp temp wage na.rm ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;lgl&gt; ## 1 株式会社リクルート 2018 2310756 388583 45856 2449 8.04 TRUE ## 2 株式会社 大丸松坂屋百貨店 2018 459840 62692 6695 3581 6.10 TRUE ## 3 株式会社 帝国ホテル 2018 58426 17307 1940 998 5.89 TRUE ## 4 株式会社 髙島屋 2018 912848 83779 7761 8849 5.04 TRUE ## 5 株式会社コメリ 2018 346862 43991 4646 4777 4.67 TRUE ## 6 株式会社オートバックスセブン 2018 213840 22139 4171 747 4.50 TRUE ## 7 株式会社ロイヤルホテル 2018 40884 13115 2049 894 4.46 TRUE ## 8 オルビス株式会社 2018 248574 28555 4181 2330 4.39 TRUE ## 9 株式会社ファンケル 2018 122496 15103 1381 2213 4.20 TRUE ## 10 近畿日本ツーリスト株式会社 2018 411821 38186 6956 2189 4.18 TRUE このように、データの中から研究課題と整合的な情報を抽出したり、変数を作成したりすることができる。ただし、研究者にとって都合の良い結果を得るために恣意的に用いるデータを制限、操作することは、研究不正となる。そのため、実際の研究では、どのようなデータ・情報を用いるかについて事前に計画しておく必要がある。 “desc”は、descending orderの略であり、降順を表す。↩︎ "],["summary.html", "データの要約と可視化", " データの要約と可視化 ここからは、記述統計や可視化によってデータを要約する方法について説明する。記述統計では、統計量と呼ばれる指標を用いてデータの特徴を数値から把握する。一方で可視化においては、図表を作成することでデータの特徴を視覚的に理解することを目的とする。実証的なマーケティング研究においては、データを用いた仮説の検証という方法が主流かもしれないが、仮説検証に用いるデータはどのようなものなのかを要約し、それを（論文やレポートの）読者へ伝えるプロセスは必要である。記述統計やデータの可視化は、このプロセスにおいて機能する方法である。 記述統計 記述統計の利用においては、データのタイプ別に利用すべき統計量が異なることに注意が必要である。データには量的変数とカテゴリ（を示す質的）変数があるが、量的変数は数値で測定できるものであり、その計算結果を解釈することも可能である。一方でカテゴリ変数は、各観測個体が属している状態やグループを表す指標であり、それを計算してもそこから含意を得るのが難しい。Rのような統計ソフトは非常に素直なので、たとえカテゴリ変数であってもそこに数値が入力されていれば、記述統計に必要な計算を実行し、結果を返してくれる。しかしながら研究においてはそれらの結果を適切に解釈する必要があり、自身が用いている変数のタイプに応じた分析を実行する必要がある。 その上で本節ではまずひとつの量的変数の情報を要約するための記述統計を紹介する。一つの数値によってデータ全体を代表させるような数値を代表値と呼ぶ。代表値は主に、データの中心を示す指標と考えられる。本節ではデータの中心を表す指標として中央値 (median) と平均値 (mean) を紹介する。中央値は、データのすべての観測値において、その値より小さな観測値の数と大きな観測値の数が等しくなるような真ん中の値を表す。そのため、（1, 3, 2, 5, 4）というデータにおける中央値は3である。これは、このデータを、1, 2, 3, 4, 5 と並べ替えると、3よりより小さな観測値の数と大きな観測値の数が等しくなっていることから確認できる3。 d &lt;- c(1, 3, 2, 5, 4) median(d) ## [1] 3 d2 &lt;- c(1, 3, 2, 5, 4, 6) median(d2) ## [1] 3.5 平均値（算術平均と呼ばれる）は、最もよく使われる代表値の一つである。平均値は、n個のデータ、\\(\\small x_1,x_2,...,x_n\\) に対して以下のように定義される。 \\[\\bar{x} = \\frac{1}{n}\\sum_i^n x_i\\] 観測値と平均値の差（\\(x_i - \\bar{x}\\)）は偏差と呼ばれ、偏差の和はゼロである（\\(\\sum_ix_i - \\bar{x}=0\\)）という性質を持つ。つまり、平均値を中心として、データの正の方向へのばらつきと負の方向へのばらつきが釣り合いが取れているということが伺える。この点が、平均値がデータの中心を表す代表値として用いられるひとつの理由である。また、平均値にはいくつかの好ましい統計的性質があるのだが、それについては後述する。Rにおいては、mean() 関数を用いることで分析が可能である。例えば、9人の生徒に対して行われた数学(x)と国語(y)のテスト(10 点満点)の結果が、それぞれ以下の通りであったとしよう。 数学: (3,3,5,5,5,5,5,7,7) 国語: (2,3,3,5,5,5,7,7,8) このときの平均値は以下のように求まる。 math &lt;- c(3,3,5,5,5,5,5,7,7) jpn &lt;- c(2,3,3,5,5,5,7,7,8) mean(math) ## [1] 5 mean(jpn) ## [1] 5 計算の結果、どちらも平均値は5であった。データの中心を表す代表値の値が等しかったため、これら2科目のテスト結果は同じ分布を持つと判断して良いのだろうか。自明かもしれないが、そのような解釈は不適切である。具体的には、データの「ばらつき」についても確認する必要がある。分布のばらつきは、平均値からの離れ方(平均値からの偏差) によって判断される事が多く、これが大きなデータが多い場合は、よりデータは散らばっ て分布していると解釈される。一方でデータが平均の近くに集まって分布している場合、ばらつきが小さいと捉えられる。この分布のばらつきは主に、分散や標準偏差という指標で測られる。 分散 (Variance, \\(S^2\\)で定義する) は以下のように、平均からの偏差の二乗の和をデータ数で割ったものだと定義される。平均からの偏差の和を計算すると、正の方向へのズレとマイナス方向へのずれがあるので、互いに相殺しあって合計は 0 になる。そこで、偏差の二乗和を用いることでデータ全体がどの程度平均からばらついているかを把握する。 \\[S^2 = \\frac{1}{n}\\sum_i^n (x_i-\\bar{x})^2\\] しかしながら、分散は元の値を二乗しているのでもとのデータと単位が異なる。そのため、分散の正の平方根 (\\(\\sqrt{\\cdot}\\)) を取った値を標準偏差と呼び、この標準偏差を用いることも多い4。なお、Rでは var() と sd() によって分散と標準偏差をそれぞれ求める。ただし、Rの関数による計算では \\(s^2=\\frac{1}{n-1}\\sum_i^n (x_i-\\bar{x})^2\\) で定義される「不偏標本分散」および「不偏標準誤差」という指標を用いる。これらの指標は、不偏性（??節参照）という統計的に好ましい性質を持っているため、分析ソフトではこちらの計算方法が用いられる。そのため、Rを用いた分散の計算値が n で割った際の手計算値と異なることがあるのでその点には注意が必要である。 var(math) ## [1] 2 var(jpn) ## [1] 4.25 先程の数学と国語のテスト結果データを用いて分散を計算すると、国語の方が分散が大きいことがわかる。つまり、両テストとも平均値は同じであるものの、国語のほうがそのスコアのばらつきが大きいことがわかる。このように、代表値とともにデータのばらつきに関する情報も踏まえてデータの特徴を把握することが好ましい。 観察されたデータと標準偏差を用いて、特定の観測結果がデータ内において「相対的に」どのような位置にいるのかを捉えることも可能になる。具体的には、任意の量的変数 \\(x_1,...,x_n\\) に対して、標準化されたスコア \\(z_1,..,z_n\\) は以下のように定義できる。 \\[ z_i=\\frac{(x_i-\\bar{x})}{\\sqrt{(S^2)}} \\] ただし、 \\(S^2\\) は変数 \\(x\\) の分散である（不偏標本分散を用いることもある）。上記定義の通り、標準化スコアは観測値の平均からの偏差を標準偏差で割っており、ある観測が平均値から標準偏差何個分ズレているかを示していると解釈できる。なお、標準化スコアは、平均が0、分散が1になることも知られている。 一方でデータの観測数（ \\(n\\) ）が偶数である場合、\\(\\small n/2\\) 番目と、\\(\\small (n/2)+1\\) 番目が中央となるため、n個のデータの観測値を、\\(x_1,x_2,...,x_n\\) とすると、これらふたつの値の平均値（ \\(\\small \\frac{x_{\\frac{n}{2}}+x_{ \\frac{n}{2}+1}}{2}\\) ）が中央値となる。Rにおいてはmedian() 関数によって以下のように計算することができる。↩︎ 偏差の二乗和のかわりに偏差の絶対値を用いた平均偏差という指標も存在する。しかしながら、分散や標準偏差のほうが好ましい統計的性質を持つことから、二乗和が用いられることが多い。↩︎ "],["categoricalVar.html", "カテゴリ変数の要約", " カテゴリ変数の要約 一方でカテゴリ変数は、代表値や分散によって含意を得るのではなく、頻度のカウント（集計）や、クロス集計を用いることが多い。これにより、各カテゴリにどれぐらいの観測数があるのかを確認することが可能になる。カテゴリ変数の内容（出現頻度）の確認には、table() 関数を用いる。また、with()関数を用いて同様の結果を得ることも可能である。ここでは、先ほど用いた firmdata から2018年度の情報を抽出し、日経業種に基づく産業の違いから、どのカテゴリの企業がどれだけデータ内にいるのかを確認する。なお、tidyverseを起動していない場合には、必要に応じて library(tidyverse) を事前に指示してほしい。 firm2018 &lt;- firmdata %&gt;% filter(fyear == 2018) table(firm2018$ind_en) ## ## Air Transportation Amusement Services Bakery Products ## 8 4 1 ## Communication Services Cosmetics &amp; Toilet Goods Department Stores ## 2 3 7 ## Foods, NEC Home &amp; Pre-Fabs Hotels ## 1 2 5 ## Miscellaneous Services Miscellaneous Wholesales Motor Vehicles ## 27 2 4 ## Musical Instrument Railroad (Major) Railroad (Minor) ## 1 27 2 ## Real Estate - Sales Retail Stores, NEC Supermarket Chains ## 1 35 14 ## Trucking ## 1 with(firm2018, table(ind_en)) また、table関数にて2つのカテゴリ変数を指定することで、両変数に対応するカテゴリの出現頻度を返してくれる。このような表のことをクロス集計表とよぶ。例えば、同データにおける広告集中的な企業を把握するため、広告集中度が中央値よりも高ければ1、それ以外であれば0を取るダミー変数（??節参照）を作成し、各産業カテゴリとの関係を確認する。 firm2018 &lt;- firm2018 %&gt;% mutate(ad_dummy = ifelse(adint &gt; median(adint),1, 0)) with(firm2018, table(ind_en,ad_dummy)) ## ad_dummy ## ind_en 0 1 ## Air Transportation 4 4 ## Amusement Services 4 0 ## Bakery Products 0 1 ## Communication Services 1 1 ## Cosmetics &amp; Toilet Goods 0 3 ## Department Stores 0 7 ## Foods, NEC 0 1 ## Home &amp; Pre-Fabs 0 2 ## Hotels 5 0 ## Miscellaneous Services 17 10 ## Miscellaneous Wholesales 1 1 ## Motor Vehicles 0 4 ## Musical Instrument 0 1 ## Railroad (Major) 27 0 ## Railroad (Minor) 2 0 ## Real Estate - Sales 0 1 ## Retail Stores, NEC 11 24 ## Supermarket Chains 2 12 ## Trucking 1 0 上の表では、各行に産業名が記載されており、その右隣に、広告集中度が低い（ad_dummy=0）企業数が、さらにその右隣には広告集中度が高い（ad_dummy=1）企業数がそれぞれ記載されている。これらのデータを確認すると、鉄道会社やアミューズメント、ホテル、トラック運送業において広告集中度が高い企業が少ないことがわかる。それ以外では産業内でも広告集中度の高い企業と低い企業とが比較的バラけている。 特定のカテゴリに着目して、カテゴリ変数についての集計を行うことも可能である。例えば、広告集中度が高い企業における産業のばらつきを調べたいときには、filter() 関数を用いれば良い。 firm2018 %&gt;% filter(ad_dummy == 1) %&gt;% with(table(ind_en)) ## ind_en ## Air Transportation Bakery Products Communication Services ## 4 1 1 ## Cosmetics &amp; Toilet Goods Department Stores Foods, NEC ## 3 7 1 ## Home &amp; Pre-Fabs Miscellaneous Services Miscellaneous Wholesales ## 2 10 1 ## Motor Vehicles Musical Instrument Real Estate - Sales ## 4 1 1 ## Retail Stores, NEC Supermarket Chains ## 24 12 カテゴリ変数と量的変数の関係を調べることも、グループ別に量的変数の要約を行う形で可能である。具体的には、 group_by() 関数を用いる。group_by() は関数内で指定した変数を用いてデータをグループ化し、グループごとの集計や処理を可能にする関数である。例えば、売上高と広告集中度の平均と標準偏差を産業ごとに確認することは、以下のような指示で可能になる。 firm2018 %&gt;% group_by(ind_en) %&gt;% summarize(obs = n(), sales_m = mean(sales), sales_sd = sd(sales), adint_m = mean(adint), adint_sd = sd(adint)) ## # A tibble: 19 × 6 ## ind_en obs sales_m sales_sd adint_m adint_sd ## &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Air Transportation 8 1772786. 305240. 0.00311 0.00333 ## 2 Amusement Services 4 298138. 263017. 0 0 ## 3 Bakery Products 1 1059442 NA 0.0122 NA ## 4 Communication Services 2 547088. 172736. 0.0231 0.0327 ## 5 Cosmetics &amp; Toilet Goods 3 140669. 100063. 0.108 0.0498 ## 6 Department Stores 7 843248. 348819. 0.0195 0.00535 ## 7 Foods, NEC 1 504153 NA 0.0229 NA ## 8 Home &amp; Pre-Fabs 2 4143505 0 0.00857 0 ## 9 Hotels 5 62135. 58060. 0 0 ## 10 Miscellaneous Services 27 311867. 456037. 0.0114 0.0204 ## 11 Miscellaneous Wholesales 2 176520 52778. 0.0203 0.0287 ## 12 Motor Vehicles 4 5279122. 4233188. 0.0254 0.00404 ## 13 Musical Instrument 1 434373 NA 0.0443 NA ## 14 Railroad (Major) 27 1302921. 1037834. 0 0 ## 15 Railroad (Minor) 2 260502 0 0 0 ## 16 Real Estate - Sales 1 1861195 NA 0.0114 NA ## 17 Retail Stores, NEC 35 571019. 547247. 0.0243 0.0272 ## 18 Supermarket Chains 14 4335164. 3511347. 0.0147 0.00782 ## 19 Trucking 1 1118094 NA 0 NA このように、カテゴリごとの量的変数の要約も実行可能である。なお、標準偏差が NA となっている箇所は、観測数が 1 であり、標準偏差を計算できない状況を表している。 "],["visualization.html", "データの可視化", " データの可視化 本サイトでのデータの可視化では、主にtidyverse内に含まれる ggplot2 というパッケージを用いる。データの可視化では、円グラフ、折れ線グラフ、帯グラフなどの様々なグラフを用いて視覚化されることも多いだろう。しかしなが本節では、主にヒストグラム、箱ひげ図、バイオリンプロットをRでの実行例とともに紹介する。これらの図は、量的変数の分布を視覚的に示すことについて優れた可視化の方法だと言える。ここでは、ggplot2に内包されている diamonds データを用いて可視化を学ぶ（tidyverseを起動することで自動的に ggplot2も起動されるため、このタイミングでtidyverseを起動していない場合には、必要に応じて library(tidyverse) によってパッケージを起動してほしい）。diamonds データについては以下のように確認できる。 head(diamonds) ## # A tibble: 6 × 10 ## carat cut color clarity depth table price x y z ## &lt;dbl&gt; &lt;ord&gt; &lt;ord&gt; &lt;ord&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 0.23 Ideal E SI2 61.5 55 326 3.95 3.98 2.43 ## 2 0.21 Premium E SI1 59.8 61 326 3.89 3.84 2.31 ## 3 0.23 Good E VS1 56.9 65 327 4.05 4.07 2.31 ## 4 0.29 Premium I VS2 62.4 58 334 4.2 4.23 2.63 ## 5 0.31 Good J SI2 63.3 58 335 4.34 4.35 2.75 ## 6 0.24 Very Good J VVS2 62.8 57 336 3.94 3.96 2.48 なお、Macのデスクトップ版でggplot2等を使うと日本語が文字化けするので、Macユーザーは別途以下のコマンドを実行する必要がある。 #For mac users theme_set(theme_gray(base_size = 10, base_family = &quot;HiraMinProN-W3&quot;)) ここではまず、ggplot2の ggplot() 関数を用いて図示化のためのオブジェクトを作成する。この関数では、以下の引数を指定する。 data: 可視化に用いるデータフレームの指定 mapping: データから抽出する変数と画面に表示される図との関係の指定 mapping内で、aes() 関数（aesthetics）で視覚化に用いる変数とプロット要素間の接続を図ることも多い。 aes() 関数は、データ内の変数がをどのように視覚的情報（美的特性）にマッピングするか（例えば、x軸とy軸の変数はなにか）を特定するための関数である。こらの引数により、ggplot関数で作成された図示化オブジェクトには、着目するデータと変数が特定される。 続いて、ggplot()で作られたオブジェクトに対して、geom (geometry) に関する情報を 追加し、グラフィックの層(layer)を加えることで図を作成する。このプロセスでは、geom_point() による散布図や、geom_histogram() によるヒストグラムなど、具体的な図表のタイプに対応する関数を利用することで、図を作成できる。また、geomに関する関数以降に labs() というラベルに関する関数を追加することで、図に必要な情報を加筆することが可能になる。 ggplot2を用いたデータ可視化の例として、まずはヒストグラムを描画する。ヒストグラムはデータの分布を離散的に示すものであり、連続変数を階級で分けて各階級の頻度を図示化する。ヒストグラムは一つの変数を扱った図なので、mapping引数ではひとつの変数を指定する。その上で作成した図示化オブジェクトに geom_histogram() を追加することでヒストグラムを描画する。以下では、ダイアモンドの価格の観測頻度についての可視化例を紹介する。以下の図では、価格の程度を離散的に区切り、その区切られた各範囲の価格を取る観測がデータ内にどれだけ存在するかを示している。 p1 &lt;- ggplot(diamonds, mapping = aes(x = price)) p1 + geom_histogram() + labs(x = &quot;価格&quot;, y = &quot;頻度&quot;, title = &quot;ヒストグラム1: ダイアモンド価格&quot;) なお、縦軸を確率密度(density)に変えるときは、geom_density()を用いる。その際、fillという引数を設定すると、密度を範囲に色を塗ることができる (なお、“p1” というオブジェクトは再利用できるので、再びggplot()によって指定する必要はない)。 p1 + geom_density(fill = &quot;black&quot;, alpha = 0.5) + labs(x = &quot;価格&quot;, y = &quot;頻度&quot;, title = &quot;ヒストグラム2: ダイアモンド価格（geom_density）&quot;) 次に、箱ひげ図の作り方を紹介する。箱ひげ図は、四分位数と四分位範囲等を図示化したものである。四分位数はデータを4等分する区切りの値であり、第一四分位はQ1、第二四分位はQ2、第三四分位はQ3、最大値はQ4で示される。四分位範囲はQ3-Q1の範囲で示されるものである。ここでは、Cutの質（Fair, Good, Very Good, Premium, Ideal）ごとに価格の分布を比べるため、複数の箱ひげ図を並べる例を提示する。 p2 &lt;- ggplot(diamonds, mapping = aes(x = cut, y = price)) p2 + geom_boxplot() + labs(x = &quot;Cutの質&quot;, y = &quot;価格&quot;, title = &quot;箱ひげ図1: ダイアモンド価格&quot;) 箱ひげ図を作成すると、ひげの上下に点が表示されることがある（上図では上部が太線のように見えている）。これは、外れ値の候補として全体の分布から離れて存在する観測値が示されている。ここで示される外れ値の候補は、Q1よりも四分位範囲\\(\\times 1.5\\) 以上小さい、ないしは、Q3よりも四分位範囲\\(\\times 1.5\\) 以上大きいかで特定される。外れ値がある場合、入力ミスなどのエラーではないか、異質な観測値でないか、を検討、確認することが必要になる。 次に紹介する図のタイプはバイオリンプロットである。バイオリンプロットは、箱ひげ図よりももう少し詳しくデータの分布を確認できる図である。ggplot2では、geom_violin() を用いる。例えば、先程の箱ひげ図をバイオリンプロットで示すと、以下のようになる。以下の図は、バイオリンプロット内に箱ひげ図を示すことでよりわかりやすい図を作成するように工夫している。 p2 + geom_violin() + geom_boxplot(fill = &quot;gray&quot;, width = 0.1) + labs(x = &quot;Cutの質&quot;, y = &quot;価格&quot;, title = &quot;バイオリンプロット: ダイアモンド価格&quot;) バイオリンプロットで横に広がっているところは、ヒストグラムで言う山が高いところを意味しており、そこに多くのデータが集まっていることを示している。 "],["cor.html", "二変数間の関係の要約", " 二変数間の関係の要約 ここまでの内容は（カテゴリ変数に関する一部の説明を除き）、一つの変数に関する要約と可視化を扱っていた。しかし、データ分析では二つの異なる変数間の関係を捉えたいと考えることも多い。二変数間の関係を数量的に要約するための指標の代表例が共分散や相関係数である。データ数をnとする変数xとyの共分散（\\(S_{xy}\\)）は、以下のように定義される。なお、Rで共分散を求める際には cov() 関数を用いる。 \\(S_{xy}=\\frac{1}{n}\\sum_i^n (x_i-\\bar{x})(y_i-\\bar{y})\\) また、\\(S^2_x\\)と\\(S^2_y\\)をそれぞれxとyの分散としたとき、相関係数（\\(\\rho_{xy}\\)5）は以下のように定義される。Rで相関係数を求める際には cor() 関数を用いる。 \\(\\rho_{xy}=\\frac{S_{xy}}{\\sqrt{S_x^2}\\cdot \\sqrt{S_y^2}}\\) 共分散は、二つのデータ間の共変動を示す指標であるものの、この数値を持って我々研究者が二変数の関係について（例えばその強弱などを）解釈するのは困難である。そこで、二変数間の関係を数値的に解釈する場合には、一般的に相関係数を用いる。相関係数は、-1 から 1 までの値を取り、正の値を取る場合は正の相関、負の値を取る場合は負の相関を示している。また、相関係数が正（負）の値かつ1に近いほど強い正（負）の相関であることが知られている。ただし、相関係数で表される二変数間の関係は、どれだけ線形関係に近いかである。言い換えると、相関が高いとはデータがどれだけ直線上に集まって分布しているかを示しており、グラフ等で示される線形関係の傾きについては何も回答することができないという点に注意が必要である。 例えば、以下のようなデータセットを考える。 X &lt;- tibble(x1 = c(-3, -1, 0, 2, 5), y1 = c(16, 12, 10, 6, 0), y2 = c(8, 6, 5, 3, 0)) X ## # A tibble: 5 × 3 ## x1 y1 y2 ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 -3 16 8 ## 2 -1 12 6 ## 3 0 10 5 ## 4 2 6 3 ## 5 5 0 0 ただし、tibble はより大規模なデータ操作が容易になる特性を持った、tidyverse 上で用いられるデータフレームの形式である。tibble() 関数を用いることで、オブジェクトとなるデータフレームをtibbleとして定義することができる。 以下の計算で示すように、このデータセットにおける x1 と y1 の相関係数は -1 であり、両者の関係を図で示すと、すべてのデータが直線上（\\(y=-2x+10\\)）に並ぶことがわかる。なお、$ はデータフレーム内の変数名を指定するための記号である（データ$変数）。一方で、x1 と y2 との相関係数も -1 であるものの、両者の線形関係は \\(y=-x+5\\)である。このことからも、相関係数が線形関数の傾きや切片についての情報は何も持たないことがわかる。なお、geom_point() は散布図を描くための関数であり、geom_smooth() は引数method で指定する方法で、データに関する近似線を描画するための関数である。ここでは、method = lm として、最小二乗法で求めた直線を描画している。 cor(X$x1, X$y1) ## [1] -1 ggplot(data = X, mapping = aes(x = x1, y = y1)) + geom_point() + geom_smooth(method = lm) また我々は、二変数間の相関係数がゼロであることが、両者が無関係であることを意味しないことにも注意をしなければならない。例えば、以下のようなデータセットにおけるA と B の相関は 0 になる。 ## # A tibble: 5 × 2 ## A B ## &lt;dbl&gt; &lt;dbl&gt; ## 1 -2 4 ## 2 -1 1 ## 3 0 0 ## 4 1 1 ## 5 2 4 cor(AB$A, AB$B) ## [1] 0 しかしながら、両者の関係を描画すると、\\(y = x^2\\) という二次関数の関係にあることがわかる。つまり、相関係数がゼロだからといって、二つの変数間に関係がないと結論づける事はできず、相関ではなく異なる複数の分析アプローチによって関係を特定していくことが必要になる。 ggplot(data = AB, mapping = aes(x = A, y = B)) + geom_point() + geom_smooth(method = lm, formula = y ~ x + I(x^2), se = FALSE) 二変数間の関係についての可視化もggplot2にて対応できる。具体的には、geom_point()という関数を用いるのだが、mappingに対する引数として、x と y 二つの変数を指定することが必要になる。ダイアモンドの価格は、カラット数に大きく依存すると考えられる。そこで、以下のようにカラット数と価格との間の共分散と相関係数を計算する。 cov(diamonds$carat,diamonds$price) ## [1] 1742.765 cor(diamonds$carat,diamonds$price) ## [1] 0.9215913 これらの変数間の相関係数は約0.92であり、高い正の相関関係であることが確認された。続いて、これらの変数の関係を可視化する。二変数間の関係を端的に可視化する方法が散布図である。散布図は、一方の変数を横軸に、もう一方の変数を縦軸に取り、各データのそれぞれの値の組み合わせをプロットしたものである。 p3 &lt;- ggplot(diamonds, mapping = aes(x = carat, y = price)) p3 + geom_point() + labs(x = &quot;カラット&quot;, y = &quot;価格&quot;, title = &quot;散布図1: カラット：価格&quot;) 研究目的によっては、二つの変数間の関係をカテゴリごとに比較したい場合もあるだろう。例えば、我々はカラットと価格の関係は、カットの質によって変わるのか、という問いに関心があるとしよう。その場合には、(1) 同一図内にてカテゴリごとに色分けする方法と、(2) カテゴリごとに分割して図示化する方法がある。それぞれのggplot2での実行方法は、以下のとおりである。 Mapping = aes() 内に、 color = categ_varと指定することで、categ_var変数のカテゴリに基づき色分けする。 facet_grid() や facet_wrap() を用いる。 まず、(1) の図内での色分け方法は、以下のようなコマンドで実行できる。 p4 &lt;- ggplot(diamonds, mapping = aes(x = carat, y = price, color = cut)) p4 + geom_point() + labs(x = &quot;カラット&quot;, y = &quot;価格&quot;, color = &quot;カット&quot;, title = &quot;散布図 2: カット別、カラット：価格&quot;) このように、mapping = aes() 内にて色付けに関する引数を設定することで散布図内の観測値を色分けできる。ただし、ここで重要なのは、color =という引数では、カテゴリ変数を指定すべきであり、色そのもの（例えば、redやblue）を指定するものではないということである。しかしながら、散布図 2のように多くのカテゴリが含まれる場合にはこの可視化の方法適さないかもしれない。そこで、以下の方法を紹介する。facet_wrap() を用いた図の作成では、散布図 2のように color 引数を指定する必要はなく、p3 を再利用できる。facet_wrap()は、関数内で指定した変数（~cut）に基づいて図を分けて描画するように指示ができる。geom_point() で散布図作成の指示を与えたあとに、facet_wrap() のレイヤーを重ねる指示を与えれば、散布図 3が作成される。 p3 + geom_point() + facet_wrap(~cut) + labs(x = &quot;カラット&quot;, y = &quot;価格&quot;, title = &quot;散布図 3: カット別、カラット：価格&quot;) 散布図 3をみると、基本的にはカラット数と価格には正の相関があるものの、カットの質が低い（例、Fair）場合にはばらつきが大きいことがうかがえる。 これまでに学んだdplyrによるデータ処理方法をパイプ演算子でつなげることで、特定の群のみを対象にした図示化も容易になる。ここでは例として、1.00カラット以上と未満とで分けて、それぞれのヒストグラムを作成してみる。 p5 &lt;- diamonds %&gt;% filter(carat &gt;= 1.0) %&gt;% ggplot(mapping = aes(x = price)) p5 + geom_histogram() + labs(x = &quot;価格&quot;, y = &quot;頻度&quot;, title = &quot;ヒストグラム:1.00カラット以上&quot;) p6 &lt;- diamonds %&gt;% filter(carat &lt; 1.0) %&gt;% ggplot(mapping = aes(x = price)) p6 + geom_histogram() + labs(x = &quot;価格&quot;, y = &quot;頻度&quot;, title = &quot;ヒストグラム:1.00カラット未満&quot;) Rで図を作成したら保存（出力）したいと考えることも多いだろう。日本語を使っていない図はggsaveを使い簡単に保存できる。具体的には、まず、作成した図そのもの（図示化のためのggplot() オブジェクトではない）をオブジェクトとして定義（例、plot1）する。ggsaveの使用例は以下の様になる (以下は見本コード)。 ggsave(filename = &quot;plot1.pdf&quot;, plot = plot1, width = 10, height = 5, units = &quot;cm&quot;) 日本語を含む頭の場合、quartz() を用いた以下の手順を経て図を保存する。 1. quartz()で作図デバイスを起動する。 2. 作図デバイスを開いたまま、Rstudio内で図を表示する。 3. dev.off()という指示で作図デバイスを閉じることで図が保存される。 また、Rstudio内のplotタブから、クリック-バイ-クリックで実行することも可能である（Export -&gt; Save as Image/ Save as PDF -&gt; Directory -&gt; File name）。 なお、\\(\\rho\\)はローと読む↩︎ "],["参考文献ch3reference.html", "参考文献{ch3reference}", " 参考文献{ch3reference} 倉田博史・星野崇宏（2011）「入門統計解析」、新世社. 高橋将宜・渡辺美智子 (2017). 「欠測データ処理」, 共立出版. 松村優哉・湯谷啓明・紀ノ定保礼・前田和寛（2021）「改訂2版 RユーザのためのRStudio[実践]入門〜tidyverseによるモダンな分析フローの世界」，技術評論社. Healy, Kieran (2018) Data Visualization: A Practical Introduction, Princeton University Press. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
