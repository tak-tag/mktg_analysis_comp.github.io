# 回帰分析{#regintro}
## 本章の概要{#ch5Intro}
二変数間の関係を捉える分析手法として  \@ref(test) 章では相関係数を紹介した。相関係数は二変数間の線形関係を表す -1から 1 の値を取る指標である。 しかしながら、相関係数は線形関係の強さ（どれだけデータが直線上に近く分布しているか）を表しているものの、示されている直線の切片や傾きといった線形関数の特徴は捉えられない。本章では、ビジネス領域で最も広く用いられる手法の一つである回帰分析を紹介する。回帰分析は、理論や産業的知識から導出された仮説を検証したり、変数間の関係について予測を行うために用いられる方法である。回帰分析の最も基本的な構造は以下のように線形関数の形で変数間の関係を捉えるモデルを定式化するものである：

$$
y_i=\alpha+\beta x_i+u_i
$$
このとき、$y_i$ は被説明変数（従属変数）、$x_i$ は説明変数（独立変数）、$u_i$ は誤差項と呼ぶ。$\alpha$ と $\beta$ はそれぞれ切片と傾きを表す係数である。経営学・マーケティング領域の研究では、これらの係数について推定・検定することが主たる目的になる事が多い。また、回帰分析では複数の説明変数を含むモデルの定式化も可能である。
本章では、Rを用いた分析手法および、分析結果の解釈について紹介する。回帰分析の原則や解釈上の注意については、別途テキストを参照してほしい。ここでは特に重要な注意点として簡単に以下の三つを紹介する。第一に回帰分析では、切片と傾きパラメータを用いた線形関数で被説明変数と説明変数の関係を示しているが、これはこれらの変数間の平均的な関係を捉えたものである。より具体的には、ある $x$ の値が与えられたときの $y$ の「平均値（期待値）」と $x$ の間には線形の関係があることを示している。第二に、ソフトウェアで回帰分析を実行すると、回帰係数に対する検定を行ってくれるが、このような検定では、「係数がゼロか否か」を検定している。そのため、係数の検定結果（統計的に有意か否か）をもとに、$x$ が $y$ に与える影響の強さや程度について議論することはできないという点に注意が必要である。第三に、重回帰モデルにおける係数解釈とその重要性について強調する。重回帰モデルにおける説明変数の係数は、同モデル内の他の変数の影響をコントロールしたうえでの説明変数が被説明変数へ与える影響を表現している。これは、説明変数が持つ変動のうち他の説明変数とは無関係な変動だけを抽出し、被説明変数との関係を分析する構造になっているためである。この特性は分析におけるコントロール変数の採用や、より信頼性の高い効果検証を目的として広く活用されている。


## 分析準備{#regpreparation}
本章では、変数間の関係を捉える回帰分析について、そのモデルの基礎と統計的推測に基づく解釈を説明する。回帰分析結果から得られる含意は、「予測」と「検証」の二つに大別することができる。その上で特に本書では、「検証」という側面、特に「研究上関心のある説明変数の係数の解釈」を重視する立場を取る。立場が異なれば、回帰分析において何を重視するかという観点も異なるため、注意してほしい。

なお本章では、\@ref(handling) 章でも利用した `MktRes_firmdata.xlsx`という企業データを用いた分析を行う。次節に移る前に以下の要領でデータを読み込んでほしい。


``` r
firmdata <- readxl::read_xlsx("data/MktRes_firmdata.xlsx")
```
本章では主に、`firmdata` における2019年のデータを抽出し、クロスセクショナルデータとして用いる。以下の様に全データから2019年の情報を抽出してほしい。


``` r
library(tidyverse)
```

```
## ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──
## ✔ dplyr     1.1.4     ✔ readr     2.1.5
## ✔ forcats   1.0.0     ✔ stringr   1.5.1
## ✔ ggplot2   3.5.2     ✔ tibble    3.3.0
## ✔ lubridate 1.9.4     ✔ tidyr     1.3.1
## ✔ purrr     1.0.4     
## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
## ✖ dplyr::filter() masks stats::filter()
## ✖ dplyr::lag()    masks stats::lag()
## ℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors
```

``` r
firmdata19 <- firmdata %>% 
  filter(fyear == 2019)
```

データを用いた分析を行う場合、取得したデータの記述統計や分布を確認する必要がある。本来であれば研究上重要な変数を対象にデータの特徴を整理するが、ここでは複数の変数の特徴を一括で整理、図示化する方法を提示する。この方法では、`GGally`というパッケージの`ggpairs()`という関数を用いるため、以下のようにパッケージをダウンロードしてほしい。

``` r
install.packages("GGally")
```

`firmdata19` データセットから、例として四つの変数を抽出して、ggpairsを実行する。これにより、各変数のヒストグラム（密度形式）と、それぞれの変数間の相関係数と散布図が同図内で示されている。また、`ggpairs()`内の引数設定によって様々な図示形式を指定できるため、興味のある人は調べてみてほしい。


``` r
firmdata19 %>% 
  select(sales, mkexp, emp, operating_profit) %>% 
GGally::ggpairs()+ labs(title = "ggpairs example")
```

<img src="04-reg_files/figure-html/ggpairs-1.png" width="672" />

なお、記述統計については既出の `summary()`関数にデータフレームを指定することで、データセット全体の記述統計を出力する。ここでは例として先程と同じ変数の記述統計を以下のように出力してみる。

``` r
ds1 <- firmdata19 %>% 
  select(sales, mkexp, emp, operating_profit) %>% 
  summary()
knitr::kable(ds1, align = "cccc")
```



|   |        sales    |        mkexp    |         emp    | operating_profit |
|:--|:---------------:|:---------------:|:--------------:|:----------------:|
|   | Min.   :  11333 | Min.   :0.01137 | Min.   :   163 |  Min.   :-40469  |
|   | 1st Qu.: 183525 | 1st Qu.:0.16714 | 1st Qu.:  3454 |  1st Qu.:  7743  |
|   | Median : 464450 | Median :0.25448 | Median :  7826 |  Median : 23904  |
|   | Mean   :1199403 | Mean   :0.29868 | Mean   : 20249 |  Mean   : 81088  |
|   | 3rd Qu.:1164243 | 3rd Qu.:0.37506 | 3rd Qu.: 24464 |  3rd Qu.: 63068  |
|   | Max.   :9878866 | Max.   :0.75650 | Max.   :160227 |  Max.   :656163  |

## 単回帰モデルと予測値{#prediction}

回帰分析絵では、二つの異なる変数 $y,~x$ の関係を $\small y=f(x)$ のように$y$を$x$の関数（$f(x)$）で示すというアイディアで分析を行う。このとき $y$ を「被説明変数（Explained variable）もしくは従属変数（dependent variable）」、$x$ を「説明変数（Explaining variable）もしくは独立変数（independent variable）」という。そして、被説明変数と説明変数の関係を特定化した式のことを一般的に回帰モデルという。最も基本的な関数型の特定方法は以下のような一次関数による特定化である。

$$
y=\beta_0+\beta_1x
$$
このとき、$\small \beta_0$ は切片、$\small \beta_1$ は傾きを表す係数であり、回帰係数と呼ばれる。


回帰モデルは線形の関係を捉えているものの、実際にデータを入手し散布図を作成すると、以下のように、直線とは異なる結果を得る。そのため、上記のモデルは正確な表現でないことがわかる。

<img src="04-reg_files/figure-html/scatterplot-1.png" width="672" />


分析者がデータとして得る情報は、$y$ や $x$ の実現値であり、回帰モデルの切片や傾きの値は直接はわからない。そこで、モデルで捉えた直線と実現値のズレを考え、得たデータから回帰モデルのパラメータ（係数）を推定するという方針をとる。モデルで捉えた直線による（係数の推定値に基づく）$y$ と$x$ の関係は、$\small x=x_i$ のとき、$y_i$ の予測値である$\small \hat{y}_i$（ワイハット）と、係数の推定値 $\small \hat{\beta}_0$、 $\small \hat{\beta}_1$ を用いて以下のように定義できる。

$$
\hat{y}_i=\hat{\beta}_0+ \hat{\beta}_1 x_i
$$

係数の推定値 $\small \hat{\beta}_0$ と $\small \hat{\beta}_1$ を求めるための計算方法は、（最尤法や積率法など）いくつかあるものの、本書では最小二乗法（Ordinary least square: OLS）という方法に着目し紹介する。OLS推定量（OLS Estimator: OLSE）の求め方の直感は、以下の図の通り、観測値と回帰直線間の距離の合計（残差平方和）を最小にするように計算される。

![OLSE概要](reg/ols.png){width=70%}


予測値のモデルで示されているのは、データを分析した結果求めたOLSEに基づく説明変数 $x_i$ と、$\small \hat{y}_i$ との関係である。$\small \hat{y}_i$ は被説明変数 $y_i$ の「予測値（predicted value）」や「理論値（fitted value）」と呼ばれるものであり、$y_i$ の観測値とは異なる値であることに注意が必要である。

Rによる回帰分析は、`lm()`という関数（linear model）を用いて簡単に実行できる。この関数内では、`lm(y ~ x, data = df)` という要領で、説明変数と被説明変数を $\sim$（チルダ）で繋いでモデルを指定する。例えば、先程の企業データにおける2019年の観測を用いて、従業員数と売上高の関係について分析するためには、以下のように分析を実行する。


``` r
reg1 <- lm(sales ~ emp, data = firmdata19)
coef(reg1)
```

```
## (Intercept)         emp 
## 22113.98050    58.14081
```



分析の結果、定数項（Intercept）は 22809.7 で、傾きは 58.1 であることがわかった。つまり、従業員数を一単位増やすと、売上高が58.1（百万円）増えることを示唆している。仮に従業員数が10人であれば、売上高の「予測値」は以下のように計算できる。

$$
22695.0=22114.0+58.1\times 10
$$

回帰分析による予測の精度を調べるために、分析したモデルがどの程度被説明変数全体の分散を説明しているか、という指標によってモデルの適合度を測る。一般的には、決定係数（$\small R^2$）という指標によってモデル適合度が示される。$\small R^2$ は以下のように定義される。

$$
R^2=1-\frac{\sum(y_i-\hat{y}_i)^2}{\sum(y_i-\bar{y})^2}=\frac{\sum(\hat{y}_i-\bar{y})^2}{\sum(y_i-\bar{y})^2}
$$

この指標は、被説明変数の分散を説明変数がどの程度説明するかの割合を表しており、0以上1以下の値を取る。例えば $\small R^2$ が0.80であるならば、被説明変数の変動の80%をモデルが説明しているということになる。そのため、$\small R^2$ は、回帰モデルの説明力として解釈される。しかしながら、予測という目的に対して近年は、機械学習などの発展的な手法が応用される事が多く、$\small R^2$ を軸に予測を行うことは少なくなってきている。

また、予測ではなく説明変数の効果（係数）についての検証や解釈に関心がある場合、回帰分析における $\small R^2$ の重要性は低くなる。特に、ビジネス分野における研究では、係数の推定や検定に焦点をあわせることが多い。本書においても、予測よりも係数に関する検証を重視する立場を取る。社会科学領域での分析では、$\small R^2$ が低くなることは珍しくない。そんな中で、「$\small R^2$ が低いからその回帰分析結果は意味がない」ということにはならない。研究者の目的が、関心のある変数同士（例、市場志向と企業成果）の関係性（有意性や影響の強さ）を検証したいというものである場合、仮に $\small R^2$ が低くても、きちんと両変数の関係を分析できる調査設計や分析を実行しているならば、その検証は有意義なものになる。つまりここで強調したいのは、係数の検証や解釈を重視して研究を行う場合、「$\small R^2$ がいくつ以上（以下）だから良い（ダメ）」という議論は目的と整合的ではなく、重要ではなくなるということである。

本節では、OLSを中心にデータから回帰係数を推定するプロセスに目を向け、予測値と決定係数について紹介した。しかしながら、先述の通り我々は多くの場合特定の変数が成果変数に与える影響の検証に関心がある。次節では確率的な視点から理論的に回帰分析を理解する事により、回帰分析の結果の解釈についてより詳しく学ぶ。

### 企業データを用いた回帰分析の実行{#lmmodel}
Rで回帰係数の検定結果を得るのは非常に簡単である。 `lm()` 関数の実行結果をストアしたオブジェクトに対して、`summary()` 関数を実行することで統計的検定結果を得ることができる。先程分析した `reg1` を再度利用すると、以下のような結果を得る。


``` r
summary(reg1)
```

```
## 
## Call:
## lm(formula = sales ~ emp, data = firmdata19)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -1834902  -280228   -34549   136598  3292521 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(>|t|)    
## (Intercept) 22113.980  89224.761   0.248    0.805    
## emp            58.141      2.569  22.628   <2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 875800 on 144 degrees of freedom
## Multiple R-squared:  0.7805,	Adjusted R-squared:  0.779 
## F-statistic:   512 on 1 and 144 DF,  p-value: < 2.2e-16
```

回帰係数の推定と検定に関する結果は `Coefficients:` の下に記載されている。推定・検定結果は表のような形式で表示されており、`Estimate` の列は回帰係数の推定結果、`Std. Error` は標準誤差（詳細は省略するが、誤差項の分散推定量の平方根）、 `t value`はt値、 `Pr(>|t|)`はp値をそれぞれ示している。そして、出力結果下欄には決定係数（`R-squared`）や自由度調整済み決定係数（`Adjusted R-squared`）、F検定結果、といったモデル適合度に関する結果が提示されている。

上記の結果を解釈するために、回帰分析における検定について説明する。ソフトウェアで自動的に出力される統計的仮説検定は、基本的には以下の帰無仮説と対立仮説を採用したものである（添字は省略）。
$$
H_0:\beta=0,~~H_1:\beta\neq0
$$
なお、R以外のソフトウェアを用いて回帰分析を実行しても係数に関する検定結果を返すが、通常はこの帰無仮説を採用した検定結果を出力する。

検定では、以下のような検定統計量を用いる。

$$
t=\frac{\hat{\beta}-\beta}{se(\hat{\beta})}
$$

$H_0$ が正しい（$\small \beta=0$）と仮定すると、検定統計量 *t* は計算可能であり、自由度（$\small n-2$）のt分布に従う。検定の手順は \@ref(nullhypo)節で紹介したのと同様、有意確率に基づく臨界値を定めた後、t 値を計算し、棄却域と採択域のどちらに入るのかを確認する。

$$
\begin{cases}
|t|>t_{\alpha/2}(n-2) & \Rightarrow \text{H0を棄却する。}\\
|t|\leq t_{\alpha/2}(n-2)& \Rightarrow \text{H0を採択する。}
\end{cases}
$$

これを踏まえて分析結果を確認すると、`emp` が `sales` に与える影響（係数: 58.132）は有意に0とは異なると理解できる。また、切片の係数推定値（Intercept）は大きな値を取っているが、統計的には0ではないとは言えないことが示されている。この項は、従業員数が0のときの企業の売上を示しており、この結果が統計的に有意ではないということは、我々の直感とも整合的である。

上記の検定によって、どうやら `emp` の係数は0ではなさそうだということが示唆された。では、具体的にどのような値を取るのだろうか。おおよその値だけでも把握したい。そこで、信頼区間を求め、おおよその確率（95%など）で真のパラメータが含まれている区間を確認する。OLSEの漸近的性質と中心極限定理により、サンプルサイズが十分に大きいとき、先述の統計量 *t* は標準正規分布に近づくことが知られている（西山ほか,2019）。

そのため、標準正規分布に基づく信頼区間の推定を応用できる。信頼係数を $\small \alpha$ とすると、以下の確率と区間の対応関係を得る。

$$
P\left(\left|\frac{\hat{\beta}-\beta}{se(\hat{\beta})}\right|\leq z_{\alpha/2}\right)=1-\alpha
$$

そして、上記を $\small \beta$ に関する不等式に変換すると、以下の信頼区間を得る。

$$
P(\hat{\beta}-se(\hat{\beta})\cdot z_{\alpha/2}\leq\beta\leq\hat{\beta}+se(\hat{\beta})\cdot z_{\alpha/2})=1-\alpha
$$

したがって、$\small [\hat{\beta}\pm se(\hat{\beta})\cdot z_{\alpha/2}]$ という観察可能な情報によって信頼区間が推定できる。Rによって信頼区間を得るには、回帰分析の結果に対して、`confint()` 関数を用いる（デフォルトで95%信頼係数が設定されている）。例えば、先程の `reg1`の結果を用いて、99%信頼区間を求めると、以下のような結果を得る。


``` r
confint(reg1,level = 0.99)
```

```
##                     0.5 %       99.5 %
## (Intercept) -210798.52845 255026.48944
## emp              51.43362     64.84799
```

したがって、`emp` の99%信頼区間が [51.4, 64.8] であることがわかった。すなわち、企業の従業員が一名多いと、売上高が 51から64 百万円高くなりそうだと解釈できる。一方で、`(Intercept)` の信頼区間には0を含んでいることが伺える。なお、`confint()` 関数によって計算される信頼区間の計算では上述の通り正規分布が仮定されており、詳しくはヘルプ（`?confint`）で確認できる。

## 重回帰モデル{#multiplereg}

本章のこれまでの内容では、回帰分析の概要や係数の検定・推定について説明した。回帰分析を実行することで得る情報は前節の内容がほとんどなのだが、モデルの特定化に関して、もう一つ重要な点が存在する。それが本節で扱う重回帰モデル（multiple regression model）の採用である。重回帰モデルとは、二つ以上の説明変数を含む回帰モデルのことである。一方で、前節で扱ったような説明変数が一つの回帰モデルのことを単回帰（simple regression model）という。回帰分析を用いた研究を行う際には、基本的に単回帰分析ではなく、重回帰分析を実行することが好ましい。通常の分析においては、ある被説明変数に対して考慮すべき説明変数は一つだけではなく、複数の説明変数を考慮すべき状況が多い。しかし、分析に不慣れな学生においては、複数の説明変数に関心がある場合であっても、複数の単回帰モデルを分析することで、それぞれの変数についての分析結果を得ようとすることが散見される（例えば、三つの説明変数の影響を捉えるために単回帰モデルを三本分析する等）。しかしながら本書では、基本的にはこのような分析アプローチは好ましくなく、複数の説明変数を含めた一本の重回帰分析を実施すべきだと主張する。

### 重回帰モデル概要{#mregIntro}

ある成果変数を説明するために、複数の説明変数が必要になることは、マーケティングリサーチにおいても珍しいことではない。例えば、ある製品のパフォーマンスを月次売上高で測るとする。マーケティング部門として、売上高に対してプロモーション施策がどれだけ貢献しているかを分析する際、プロモーションと売上高の関係を回帰分析で捉えるというアプローチが実現可能な分析方法として考えられる。

しかしながら、売上高を説明する変数はプロモーションだけで十分だろうか。マーケティング変数に着目するだけでも、価格や製品品質、流通網など、異なる変数が売上に関係していることが考えられる。例えば、一見プロモーションによる効果のような結果を得たとしても、実際にはその製品の価格による影響であり、プロモーションそのものにはあまり効果がないかもしれない。そのため、他の要素の影響を排除した上での純粋なプロモーション効果を明らかにすることは実務的に有意義な研究課題となりうる。そして、このような研究課題に対応する分析方法が、重回帰分析である。


重回帰分析においても単回帰同様、回帰モデルを記述することができる。*k* 個の説明変数を含む重回帰モデルは、以下のように示される。

$$
y_i = \beta_0+\beta_1x_{1i}+\beta_2x_{2i}+...+\beta_kx_{ki}+u_i
$$

論文やレポート内に重回帰モデルを記載する際にも、多くの場合上記の誤差項を含む理論モデルを用いる。

### 回帰係数の解釈{#mreginterpret}
ここからは、重回帰分析の係数の解釈について説明する。ここで説明する解釈は「なぜ基本的には重回帰モデルを採用すべきなのか」を理解するために重要な内容である。結論から述べると、重回帰分析における説明変数の係数は、「説明変数が持つ変動のうち他の説明変数とは無関係な変動だけを抽出し、被説明変数との関係を分析している」と解釈できる。この特徴が、同モデル内の「他の変数の影響をコントロールしたうえで」説明変数が被説明変数へ与える影響を捉える方法として、学術的にも実務的にも活用されている。

重回帰モデルにおける各説明変数の係数は、パーシャル効果として解釈できる。以下では、このパーシャル効果の直感について、Wooldridge（2012）を参考に説明する。まず、以下のような説明変数が二個である重回帰モデルを考える。

$$
y_i=\beta_0+\beta_1x_{1i}+\beta_2x_{2i}+u
$$
そして、上のモデルにおける予測値は以下のように示すことができる。

$$
\hat{y}_i=\hat{\beta}_0+\hat{\beta}_1x_{1i}+\hat{\beta}_2x_{2i}
$$

このとき、説明変数 $\small x_1$ と $\small x_2$ の変化をそれぞれ、 $\small \Delta x_{1i}$ と $\small \Delta x_{2i}$ とすると、予測値の変化（$\small \Delta \hat{y}$）は以下のように表すことができる。

$$
\Delta\hat{y}_i=\hat{\beta}_1\Delta x_{1i}+\hat{\beta}_2\Delta x_{2i}
$$

ここで、$\small x_2$ を固定（$\small \Delta x_{2i}=0$）すると、以下を得る。

$$
\Delta\hat{y}_i=\hat{\beta}_1\Delta x_{1i}
$$
つまり、重回帰モデルにおける $\hat{\beta}_1$ は、別の説明変数を固定（$\small \Delta x_{2i}=0$）した上で、$\small x_1$ が $\small \hat{y}$ に与える影響（$\small x_1$ が変化した際の $\small \hat{y}$の変化の程度）を捉えていると解釈できる。また、$\small \hat{\beta}_2$ についても同様に解釈できる。そしてこの特徴は、*k*個の説明変数を用いたモデルにも同様に適応できる。

## 単回帰モデルと重回帰モデルの比較{#modelcomp}
先述のパーシャル効果という重回帰モデルの特徴は、どのように応用できるのだろうか。多くの実証研究では、重回帰モデルの特徴を利用し、「コントロール変数」を用いた分析を行っている。本節では、先程の企業データを用いて、「企業の広告支出が営業利益に与える影響を明らかにする」という問いを考える。まずは、学習的意図から以下のように単回帰分析を実施してみる（通常の論文・レポートであればこのような過程は必要ない）。


``` r
reg2 <- lm(operating_profit ~ adv, data = firmdata19)
summary(reg2)
```

```
## 
## Call:
## lm(formula = operating_profit ~ adv, data = firmdata19)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -450526  -55552  -40672    -791  599084 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(>|t|)    
## (Intercept) 5.708e+04  1.057e+04   5.401 2.68e-07 ***
## adv         1.257e+00  2.159e-01   5.823 3.61e-08 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 117600 on 144 degrees of freedom
## Multiple R-squared:  0.1906,	Adjusted R-squared:  0.185 
## F-statistic: 33.91 on 1 and 144 DF,  p-value: 3.613e-08
```

``` r
confint(reg2)
```

```
##                    2.5 %       97.5 %
## (Intercept) 36189.311039 77968.894422
## adv             0.830362     1.683719
```

分析の結果、広告支出（`adv`）の係数は正に有意であり、その95%信頼区間は [0.83, 1.68] であることが確認できた。

しかしながら、このモデル化は不十分であり他の要素も考慮すべきである。営業利益に影響を与えうる要因は色々とあり、実際の研究においては先行研究を参照しつつ、コントロールすべき変数を含める形で回帰モデルを特定する必要がある。ここでは便宜上いくつかの要因にのみ焦点を合わせて簡単に特定化する。本データは主に小売・サービス産業の企業に焦点を合わせている。そのため、対人サービス水準は企業のパフォーマンスに影響を与えうる要因である。そのため、従業員に関する変数（従業員数: emp、パートタイム従業員数: temp）と人件費（labor_cost）をモデルに含める。また、資産合計（total_assets）、研究開発費（rd）もモデルに含める。今回の回帰モデルは以下のように示される。

$$
\text{opretating_profit}_i = \beta_0 + \beta_1 adv_i + \beta_2emp_i+\beta_3temp_i+\beta_4\text{labor_cost}_i+\beta_5\text{total_assets}_i+\beta_6rd_i+u_i
$$
Rにおいて重回帰分析を実行するのは簡単である。`lm(y ~ x1 + x2 + x3)` のように $+$ 記号と変数を追加すれば、重回帰モデルとして分析を実行してくれる。


``` r
reg3 <- lm(operating_profit ~ adv + temp + emp + labor_cost + total_assets + rd, data = firmdata19)
summary(reg3)
```

```
## 
## Call:
## lm(formula = operating_profit ~ adv + temp + emp + labor_cost + 
##     total_assets + rd, data = firmdata19)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -360544  -27618  -15279    3467  284094 
## 
## Coefficients:
##                Estimate Std. Error t value Pr(>|t|)    
## (Intercept)   2.209e+04  8.114e+03   2.723  0.00731 ** 
## adv          -1.431e+00  2.954e-01  -4.845 3.34e-06 ***
## temp         -1.878e+00  6.313e-01  -2.975  0.00346 ** 
## emp          -1.510e+00  7.036e-01  -2.146  0.03358 *  
## labor_cost    8.808e-01  1.692e-01   5.207 6.76e-07 ***
## total_assets  3.516e-02  5.840e-03   6.020 1.47e-08 ***
## rd            1.385e+00  5.268e-01   2.629  0.00953 ** 
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 78940 on 139 degrees of freedom
## Multiple R-squared:  0.6479,	Adjusted R-squared:  0.6327 
## F-statistic: 42.63 on 6 and 139 DF,  p-value: < 2.2e-16
```

``` r
confint(reg3)
```

```
##                      2.5 %        97.5 %
## (Intercept)  6048.51599480  3.813231e+04
## adv            -2.01511513 -8.470054e-01
## temp           -3.12602311 -6.298318e-01
## emp            -2.90144939 -1.190356e-01
## labor_cost      0.54637427  1.215313e+00
## total_assets    0.02361376  4.670793e-02
## rd              0.34334525  2.426472e+00
```

見ての通り、結果の出力方式そのものは単回帰分析のものとほぼ同様である。回帰係数の結果の下にあるモデル適合度については前節を参照して欲しい。

分析の結果、広告支出の係数は「負」に有意であり、その信頼区間も [-2.01, -0.85] であった。したがって、本データの分析によると、労働や資産に加え研究開発といった側面を一定とすると、広告支出は営業利益に対して負の関係を持っていることがわかった。他の変数に着目すると、従業員数に関する変数はどちらも負に有意であった。一方で、人件費と総資産、研究開発費は正に有意な影響を与えることが示された。これらの結果から、単純に従業員数を増やしても営業利益には負の影響を与える一方で、従業員数を一定とした上で人件費を上げるほうが営業利益が高いことが示された。また、資産や研究開発費も営業利益につながることが示された。

このように、重回帰モデルを採用し複数の説明変数を含めることで、各係数の持つ含意が大きく変わることに注意して欲しい。また、`reg2` と `reg3`の比較のように、特定の説明変数に対応する係数の符号が変わることも珍しくない。そのため、回帰モデルの定式化には非常に慎重になる必要があり、先述の通り、先行研究を参照して必要な変数をコントロールすることが求められる。


## 参考文献

秋山裕（2018）「Rによる計量経済学 第2版」，オーム社.

西山慶彦・新谷元嗣・川口大司・奥井亮（2019）「計量経済学」，有斐閣.

Nishikawa, H., Schreier, M., Fuchs, C., & Ogawa, S. (2017). The Value of Marketing Crowdsourced New Products as Such: Evidence from Two Randomized Field Experiments. *Journal of Marketing Research*, 54(4), 525-539.

Wooldridge, J. (2012) *Introductory Econometrics A Modern Approach*,Cengage Learning.
